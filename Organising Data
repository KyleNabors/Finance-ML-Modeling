import os
import nltk

#Open Download Editor
#nltk.download()

import ssl
nltk.download("stopwords") 
import numpy as np
import json
import glob
import gensim
import gensim.corpora as corpora
from gensim.utils import simple_preprocess
from gensim.models import CoherenceModel
import spacy
from nltk.corpus import stopwords
import pyLDAvis
import pyLDAvis.gensim
import warnings
import matplotlib.pyplot as plt
import pandas as pd
warnings.filterwarnings("ignore",category=DeprecationWarning)
import pdfplumber
import PyPDF2
from gensim.models import Word2Vec
from gensim.utils import simple_preprocess
import pdfplumber

final = []
files = glob.glob("/Users/kylenabors/Documents/GitHub/MS-Thesis/Training Data/Fed Data/*.pdf")
for file in files:
    file = file.replace("\\", "/")
    with pdfplumber.open(file) as pdf:
        for page in pdf.pages:
            text = page.extract_text()
            segments = text.split(". ")
            for segment in segments:
                segment = simple_preprocess(segment, deacc=True)
                if len(segment) > 5:
                    final.append(segment)


def load_data(file):
    with open(file, "r", encoding="utf-8") as f:
        data = json.load(f)
    return data

def write_data(file, data):
    with open(file, "w", encoding="utf-8") as f:
        json.dump(data, f, indent=4)
        
write_data("/Users/kylenabors/Documents/GitHub/MS-Thesis/Training Data/Fed Data/fed_data.json", final)

segments = load_data("/Users/kylenabors/Documents/GitHub/MS-Thesis/Training Data/Fed Data/fed_data.json")

model = Word2Vec(segments, min_count=1, workers=3, window=3, sg=1)
model.save("/Users/kylenabors/Documents/GitHub/MS-Thesis/Models/fed_word2vec.model")

model = Word2Vec.load("/Users/kylenabors/Documents/GitHub/MS-Thesis/Models/fed_word2vec.model")
