{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the necessary libraries\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import ticker\n",
    "import numpy as np\n",
    "\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/kylenabors/Documents/GitHub/Finance-ML-Modeling\n",
      "/Users/kylenabors/Documents/GitHub/Finance-ML-Modeling\n",
      "/Users/kylenabors/Documents\n",
      "/Users/kylenabors/Documents/GitHub/Finance-ML-Modeling\n"
     ]
    }
   ],
   "source": [
    "# Importing Configs\n",
    "# Define the path where config.py is located\n",
    "# Mac\n",
    "os.chdir(\"/Users/kylenabors/Documents/GitHub/Finance-ML-Modeling\")\n",
    "# Linux\n",
    "# os.chdir('/home/kwnabors/Documents/GitHub/Finance-ML-Modeling')\n",
    "config_file_path = os.getcwd()\n",
    "print(config_file_path)\n",
    "\n",
    "# Add this path to the sys.path\n",
    "sys.path.append(config_file_path)\n",
    "\n",
    "import config\n",
    "\n",
    "# Configs\n",
    "finbert_models = config.finbert_models\n",
    "Body = config.Body\n",
    "database = config.Local_Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['positive', 'negative', 'neutral'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 12\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# state = state.groupby('date').mean().reset_index()\u001b[39;00m\n\u001b[1;32m      9\u001b[0m mins \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfinbert_models\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mBody\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/Minutes/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mBody\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_Minutes_finbert_model_short.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     11\u001b[0m )\n\u001b[0;32m---> 12\u001b[0m mins \u001b[38;5;241m=\u001b[39m \u001b[43mmins\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdate\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msentiment\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpositive\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnegative\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mneutral\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# mins = mins.groupby('date').mean().reset_index()\u001b[39;00m\n\u001b[1;32m     15\u001b[0m state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/frame.py:3767\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3765\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   3766\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 3767\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   3769\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   3770\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/indexes/base.py:5877\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   5874\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   5875\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 5877\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5879\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   5880\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   5881\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/indexes/base.py:5941\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   5938\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   5940\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m-> 5941\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['positive', 'negative', 'neutral'] not in index\""
     ]
    }
   ],
   "source": [
    "# Import Sentiment Data\n",
    "state = pd.read_csv(\n",
    "    f\"{finbert_models}/{Body}/Statements/{Body}_Statements_finbert_model_short.csv\"\n",
    ")\n",
    "# state = state[['date','sentiment', 'positive', 'negative', 'neutral']]\n",
    "state = state[[\"date\", \"sentiment\"]]\n",
    "# state = state.groupby('date').mean().reset_index()\n",
    "\n",
    "mins = pd.read_csv(\n",
    "    f\"{finbert_models}/{Body}/Minutes/{Body}_Minutes_finbert_model_short.csv\"\n",
    ")\n",
    "mins = mins[[\"date\", \"sentiment\", \"positive\", \"negative\", \"neutral\"]]\n",
    "# mins = mins.groupby('date').mean().reset_index()\n",
    "\n",
    "state[\"date\"] = pd.to_datetime(state[\"date\"])\n",
    "# mins['date'] = pd.to_datetime(mins['date'])\n",
    "\n",
    "# state = pd.merge(state, mins, on='date', how='outer')\n",
    "# state['sentiment_x'] = state['sentiment_x'].fillna(state['sentiment_y'])\n",
    "# state['sentiment_y'] = state['sentiment_y'].fillna(state['sentiment_x'])\n",
    "# state['sentiment'] = state[['sentiment_x', 'sentiment_y']].mean(axis=1)\n",
    "# print(state.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mins = pd.read_csv(\n",
    "    f\"{finbert_models}/{Body}/Minutes/{Body}_Minutes_finbert_model_short.csv\"\n",
    ")\n",
    "state[\"sentiment\"].value_counts().sort_index(ascending=True).plot(kind=\"bar\")\n",
    "plt.title(\"Sentiment Distribution of Minutes\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fedfunds = pd.read_csv(f\"{database}/Market Data/Fed Funds/Fed Funds.csv\")\n",
    "fedfunds = fedfunds[[\"date\", \"fedfunds\"]]\n",
    "fedfunds[\"date\"] = pd.to_datetime(fedfunds[\"date\"])\n",
    "\n",
    "state = pd.merge(state, fedfunds, on=\"date\", how=\"outer\")\n",
    "\n",
    "state[\"diff\"] = state[\"fedfunds\"].diff()\n",
    "\n",
    "state[\"event\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Event\n",
    "state[\"event\"] = np.where((state[\"sentiment\"].notna() == True), 1, 0)\n",
    "\n",
    "# High Rates\n",
    "# state['event'] = np.where((state['fedfunds'] > state['fedfunds'].mean()) & (state['sentiment'].notna() == True), 1, 0)\n",
    "\n",
    "# Rate Hike\n",
    "# state['event'] = np.where((state['diff'] >= 0.25) & (state['sentiment'].notna() == True), 1, 0)\n",
    "\n",
    "# Rate cut\n",
    "# state['event'] = np.where((state['diff'] <= -0.25) & (state['sentiment'].notna() == True), 1, 0)\n",
    "\n",
    "# Positive Sentiment\n",
    "# state = state[(state['sentiment'] > state['sentiment'].mean())]\n",
    "\n",
    "# Negative Sentiment\n",
    "# state = state[(state['sentiment'] < state['sentiment'].mean())]\n",
    "\n",
    "state = state[[\"date\", \"sentiment\", \"event\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe with a column date that ranges from 1990-01-01 to 2024-01-01 with a daily frequency\n",
    "# This is used to merge the dataframes\n",
    "date_rng = pd.date_range(start=\"1/1/1990\", end=\"1/1/2024\", freq=\"D\")\n",
    "date_rng = pd.DataFrame(date_rng, columns=[\"date\"])\n",
    "date_rng[\"temp\"] = 1\n",
    "state = pd.merge(date_rng, state, on=\"date\", how=\"outer\")\n",
    "state = state[[\"date\", \"sentiment\", \"event\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Market Data\n",
    "sp500 = pd.read_csv(f\"{database}/Market Data/SP500/SP500.csv\")\n",
    "sp500 = sp500[[\"date\", \"price\", \"volume\"]]\n",
    "sp500[\"volume\"] = sp500[\"volume\"] / 1000000\n",
    "sp500 = sp500.rename(columns={\"price\": \"sp500_price\", \"volume\": \"sp500_volume\"})\n",
    "\n",
    "emini = pd.read_csv(f\"{database}/Market Data/E Mini/E Mini SP500.csv\")\n",
    "emini = emini[[\"date\", \"price\"]]\n",
    "emini = emini.rename(columns={\"price\": \"emini_price\"})\n",
    "\n",
    "eurodollar = pd.read_csv(f\"{database}/Market Data/Eurodollar/Eurodollar.csv\")\n",
    "eurodollar = eurodollar[[\"date\", \"price\"]]\n",
    "eurodollar = eurodollar.rename(columns={\"price\": \"eurodollar_price\"})\n",
    "\n",
    "fedfutures = pd.read_csv(f\"{database}/Market Data/Fed Futures/FFF 30 Day.csv\")\n",
    "fedfutures = fedfutures[[\"date\", \"price\"]]\n",
    "fedfutures = fedfutures.rename(columns={\"price\": \"fedfutures_price\"})\n",
    "\n",
    "vix = pd.read_csv(f\"{database}/Market Data/VIX/VIX.csv\")\n",
    "vix = vix[[\"date\", \"sentiment\"]]\n",
    "vix = vix.rename(columns={\"sentiment\": \"vix_sentiment\"})\n",
    "\n",
    "unemployment = pd.read_csv(f\"{database}/Market Data/Unemployment/Unemployment.csv\")\n",
    "unemployment = unemployment[[\"date\", \"unemployment\"]]\n",
    "\n",
    "inflation = pd.read_csv(f\"{database}/Market Data/Inflation/Inflation.csv\")\n",
    "inflation = inflation[[\"date\", \"inflation\"]]\n",
    "\n",
    "fedfunds = pd.read_csv(f\"{database}/Market Data/Fed Funds/Fed Funds.csv\")\n",
    "fedfunds = fedfunds[[\"date\", \"fedfunds\"]]\n",
    "\n",
    "pce = pd.read_csv(f\"{database}/Market Data/PCE/PCE.csv\")\n",
    "pce = pce.rename(columns={\"PCEC_PC1\": \"PCE\", \"DATE\": \"date\"})\n",
    "\n",
    "gdp = pd.read_csv(f\"{database}/Market Data/GDP/GDP.csv\")\n",
    "gdp = gdp.rename(columns={\"DATE\": \"date\", \"GDPC1\": \"GDP\"})\n",
    "\n",
    "gdpdef = pd.read_csv(f\"{database}/Market Data/GDPDEF/GDPDEF.csv\")\n",
    "gdpdef = gdpdef.rename(columns={\"DATE\": \"date\", \"GDPDEF_PC1\": \"gdpdef\"})\n",
    "\n",
    "gdppot = pd.read_csv(f\"{database}/Market Data/GDPPOT/GDPPOT.csv\")\n",
    "gdppot = gdppot.rename(columns={\"DATE\": \"date\"})\n",
    "\n",
    "spreturn = pd.read_csv(f\"{database}/Market Data/SP500/SP500 Returns Daily.csv\")\n",
    "spreturn = spreturn.rename(columns={\"caldt\": \"date\", \"vwretd\": \"sp500_return\"})\n",
    "# remove dates from date row that are \"#NAME?\"\n",
    "# spreturn = spreturn[spreturn['date'] != '#NAME?']\n",
    "\n",
    "taylor_euro = pd.read_excel(f\"{database}/Market Data/Taylor/Taylor Rule Euro Zone.xlsx\")\n",
    "\n",
    "stoxx = pd.read_excel(\n",
    "    f\"{database}/Market Data/STOXX/STOXX 600 Daily Returns Gross Dividends.xlsx\"\n",
    ")\n",
    "\n",
    "\n",
    "euro_funds = pd.read_csv(\n",
    "    f\"{database}/Market Data/Euro Key Rate/Eurozone Key Interest Rate.csv\"\n",
    ")\n",
    "euro_funds[\"date\"] = pd.to_datetime(euro_funds[\"date\"])\n",
    "euro_funds = euro_funds.rename(columns={\"rate\": \"euro_funds\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conveting date to datetime\n",
    "\n",
    "sp500[\"date\"] = pd.to_datetime(sp500[\"date\"])\n",
    "emini[\"date\"] = pd.to_datetime(emini[\"date\"])\n",
    "eurodollar[\"date\"] = pd.to_datetime(eurodollar[\"date\"])\n",
    "fedfutures[\"date\"] = pd.to_datetime(fedfutures[\"date\"])\n",
    "vix[\"date\"] = pd.to_datetime(vix[\"date\"])\n",
    "unemployment[\"date\"] = pd.to_datetime(unemployment[\"date\"])\n",
    "inflation[\"date\"] = pd.to_datetime(inflation[\"date\"])\n",
    "fedfunds[\"date\"] = pd.to_datetime(fedfunds[\"date\"])\n",
    "pce[\"date\"] = pd.to_datetime(pce[\"date\"])\n",
    "gdp[\"date\"] = pd.to_datetime(gdp[\"date\"])\n",
    "gdppot[\"date\"] = pd.to_datetime(gdppot[\"date\"])\n",
    "gdpdef[\"date\"] = pd.to_datetime(gdpdef[\"date\"])\n",
    "spreturn[\"date\"] = pd.to_datetime(spreturn[\"date\"])\n",
    "stoxx[\"date\"] = pd.to_datetime(stoxx[\"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the first and last dates of every dataframe\n",
    "print(f\"State: {state.date.min()} - {state.date.max()}\")\n",
    "print(f\"Mins: {mins.date.min()} - {mins.date.max()}\")\n",
    "print(f\"SP500: {sp500.date.min()} - {sp500.date.max()}\")\n",
    "print(f\"E Mini: {emini.date.min()} - {emini.date.max()}\")\n",
    "print(f\"Eurodollar: {eurodollar.date.min()} - {eurodollar.date.max()}\")\n",
    "print(f\"Fed Futures: {fedfutures.date.min()} - {fedfutures.date.max()}\")\n",
    "print(f\"VIX: {vix.date.min()} - {vix.date.max()}\")\n",
    "print(f\"Unemployment: {unemployment.date.min()} - {unemployment.date.max()}\")\n",
    "print(f\"Inflation: {inflation.date.min()} - {inflation.date.max()}\")\n",
    "print(f\"Fed Funds: {fedfunds.date.min()} - {fedfunds.date.max()}\")\n",
    "print(f\"PCE: {pce.date.min()} - {pce.date.max()}\")\n",
    "print(f\"GDP: {gdp.date.min()} - {gdp.date.max()}\")\n",
    "print(f\"GDPDEF: {gdpdef.date.min()} - {gdpdef.date.max()}\")\n",
    "print(f\"GDPPOT: {gdppot.date.min()} - {gdppot.date.max()}\")\n",
    "print(f\"SP500 Return: {spreturn.date.min()} - {spreturn.date.max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "market = date_rng.copy(deep=True)\n",
    "market = market[[\"date\"]]\n",
    "market = pd.merge(market, sp500, on=\"date\", how=\"outer\")\n",
    "market = pd.merge(market, emini, on=\"date\", how=\"outer\")\n",
    "market = pd.merge(market, eurodollar, on=\"date\", how=\"outer\")\n",
    "market = pd.merge(market, fedfutures, on=\"date\", how=\"outer\")\n",
    "market = pd.merge(market, vix, on=\"date\", how=\"outer\")\n",
    "market = pd.merge(market, unemployment, on=\"date\", how=\"outer\")\n",
    "market = pd.merge(market, inflation, on=\"date\", how=\"outer\")\n",
    "market = pd.merge(market, fedfunds, on=\"date\", how=\"outer\")\n",
    "market = pd.merge(market, pce, on=\"date\", how=\"outer\")\n",
    "market = pd.merge(market, gdp, on=\"date\", how=\"outer\")\n",
    "market = pd.merge(market, gdppot, on=\"date\", how=\"outer\")\n",
    "market = pd.merge(market, gdpdef, on=\"date\", how=\"outer\")\n",
    "market = pd.merge(market, spreturn, on=\"date\", how=\"outer\")\n",
    "market = pd.merge(market, taylor_euro, on=\"date\", how=\"outer\")\n",
    "market = pd.merge(market, euro_funds, on=\"date\", how=\"outer\")\n",
    "market = pd.merge(market, stoxx, on=\"date\", how=\"outer\")\n",
    "\n",
    "market = market.sort_values(by=\"date\")\n",
    "\n",
    "market[\"unemployment\"] = market[\"unemployment\"].fillna(method=\"ffill\")\n",
    "market[\"inflation\"] = market[\"inflation\"].fillna(method=\"ffill\")\n",
    "\n",
    "market = market.fillna(method=\"ffill\")\n",
    "\n",
    "market.to_csv(f\"{database}/Market Data/All Market Data.csv\", index=False)\n",
    "\n",
    "state = pd.merge(state, market, on=\"date\", how=\"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(state.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace NaN with 0\n",
    "state[\"event\"] = state[\"event\"].fillna(0)\n",
    "# Sort state by date assending\n",
    "state = state.sort_values(by=\"date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a column that is the number of days since the last event for up to 10 days after the event\n",
    "state[\"days_since_event\"] = (\n",
    "    state[\"event\"]\n",
    "    .groupby((state[\"event\"] != state[\"event\"].shift()).cumsum())\n",
    "    .cumcount()\n",
    ")\n",
    "state[\"days_since_event\"] = state[\"days_since_event\"] + 1\n",
    "# If state state['days_since_event'] is greater than 10, set it to nan\n",
    "state[\"days_since_event\"] = np.where(\n",
    "    state[\"days_since_event\"] > 30, np.nan, state[\"days_since_event\"]\n",
    ")\n",
    "# If event = 1 sent days_since_event to 0\n",
    "state[\"days_since_event\"] = np.where(state[\"event\"] == 1, 0, state[\"days_since_event\"])\n",
    "\n",
    "# Now do the same thing but for 10 days leading up to the event\n",
    "state[\"days_until_event\"] = (\n",
    "    state[\"event\"][::-1]\n",
    "    .groupby((state[\"event\"][::-1] != state[\"event\"][::-1].shift()).cumsum())\n",
    "    .cumcount()[::-1]\n",
    ")\n",
    "state[\"days_until_event\"] = state[\"days_until_event\"] + 1\n",
    "# If state state['days_until_event'] is greater than 10, set it to nan\n",
    "state[\"days_until_event\"] = np.where(\n",
    "    state[\"days_until_event\"] > 10, np.nan, state[\"days_until_event\"]\n",
    ")\n",
    "# If event = 1 sent days_until_event to 0\n",
    "state[\"days_until_event\"] = np.where(state[\"event\"] == 1, 0, state[\"days_until_event\"])\n",
    "state[\"days_until_event\"] = state[\"days_until_event\"] * -1\n",
    "\n",
    "# create column event_count that is the combonation of days_since_event and days_until_event where it is na if both are na\n",
    "state[\"event_count\"] = state[\"days_since_event\"].fillna(state[\"days_until_event\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = state[\n",
    "    [\n",
    "        \"date\",\n",
    "        \"sp500_price\",\n",
    "        \"sp500_volume\",\n",
    "        \"emini_price\",\n",
    "        \"eurodollar_price\",\n",
    "        \"fedfutures_price\",\n",
    "        \"vix_sentiment\",\n",
    "        \"event_count\",\n",
    "        \"unemployment\",\n",
    "        \"inflation\",\n",
    "        \"fedfunds\",\n",
    "        \"sp500_return\",\n",
    "    ]\n",
    "]\n",
    "state = state.dropna()\n",
    "\n",
    "state = state.groupby(\"event_count\").mean().reset_index()\n",
    "\n",
    "# create a graph of the mean of the market varaibles over the 10 days leading up to and after the event with all the variables scaled between -1 and 1\n",
    "state[\"sp500_price\"] = (state[\"sp500_price\"] - state[\"sp500_price\"].mean()) / (\n",
    "    state[\"sp500_price\"].max() - state[\"sp500_price\"].min()\n",
    ")\n",
    "# state['sp500_std_30'] = (state['sp500_std_30'] - state['sp500_std_30'].mean()) / (state['sp500_std_30'].max() - state['sp500_std_30'].min())\n",
    "# state['sp500_std_mean'] = (state['sp500_std_mean'] - state['sp500_std_mean'].mean()) / (state['sp500_std_mean'].max() - state['sp500_std_mean'].min())\n",
    "state[\"sp500_volume\"] = (state[\"sp500_volume\"] - state[\"sp500_volume\"].mean()) / (\n",
    "    state[\"sp500_volume\"].max() - state[\"sp500_volume\"].min()\n",
    ")\n",
    "state[\"emini_price\"] = (state[\"emini_price\"] - state[\"emini_price\"].mean()) / (\n",
    "    state[\"emini_price\"].max() - state[\"emini_price\"].min()\n",
    ")\n",
    "state[\"eurodollar_price\"] = (\n",
    "    state[\"eurodollar_price\"] - state[\"eurodollar_price\"].mean()\n",
    ") / (state[\"eurodollar_price\"].max() - state[\"eurodollar_price\"].min())\n",
    "state[\"fedfutures_price\"] = (\n",
    "    state[\"fedfutures_price\"] - state[\"fedfutures_price\"].mean()\n",
    ") / (state[\"fedfutures_price\"].max() - state[\"fedfutures_price\"].min())\n",
    "state[\"vix_sentiment\"] = (state[\"vix_sentiment\"] - state[\"vix_sentiment\"].mean()) / (\n",
    "    state[\"vix_sentiment\"].max() - state[\"vix_sentiment\"].min()\n",
    ")\n",
    "state[\"unemployment\"] = (state[\"unemployment\"] - state[\"unemployment\"].mean()) / (\n",
    "    state[\"unemployment\"].max() - state[\"unemployment\"].min()\n",
    ")\n",
    "state[\"inflation\"] = (state[\"inflation\"] - state[\"inflation\"].mean()) / (\n",
    "    state[\"inflation\"].max() - state[\"inflation\"].min()\n",
    ")\n",
    "state[\"fedfunds\"] = (state[\"fedfunds\"] - state[\"fedfunds\"].mean()) / (\n",
    "    state[\"fedfunds\"].max() - state[\"fedfunds\"].min()\n",
    ")\n",
    "state[\"sp500_return\"] = (state[\"sp500_return\"] - state[\"sp500_return\"].mean()) / (\n",
    "    state[\"sp500_return\"].max() - state[\"sp500_return\"].min()\n",
    ")\n",
    "\n",
    "\n",
    "# Plot the data\n",
    "fig, ax = plt.subplots(figsize=(25, 15))\n",
    "# ax.plot(state['event_count'], state['sp500_price'], label='SP500 Price')\n",
    "# ax.plot(state['event_count'], state['sp500_volume'], label='SP500 Volume')\n",
    "# ax.plot(state['event_count'], state['emini_price'], label='E Mini Price')\n",
    "# ax.plot(state['event_count'], state['eurodollar_price'], label='Eurodollar Price')\n",
    "# ax.plot(state['event_count'], state['fedfutures_price'], label='Fed Futures Price')\n",
    "# ax.plot(state['event_count'], state['vix_sentiment'], label='VIX Sentiment')\n",
    "# ax.plot(state['event_count'], state['unemployment'], label='Unemployment')\n",
    "# ax.plot(state['event_count'], state['inflation'], label='Inflation')\n",
    "ax.plot(state[\"event_count\"], state[\"fedfunds\"], label=\"Fed Funds\")\n",
    "ax.plot(state[\"event_count\"], state[\"sp500_return\"], label=\"sp500_return\")\n",
    "\n",
    "ax.xaxis.set_major_locator(ticker.MaxNLocator(10))\n",
    "\n",
    "ax.set_xticks(state[\"event_count\"])\n",
    "\n",
    "# Set Y axis sale to -1 to 1\n",
    "ax.set_ylim(-1, 1)\n",
    "\n",
    "# #Add a vertical line at all days +-10 Days from the event\n",
    "# for i in range(0, 11):\n",
    "#     ax.axvline(x=i, color='gray', linestyle='--', alpha=0.5)\n",
    "#     ax.axvline(x=i * -1, color='gray', linestyle='--', alpha=0.5)\n",
    "\n",
    "# Add a vertical line at all days 25 Days from the event\n",
    "for i in range(0, 31):\n",
    "    ax.axvline(x=i, color=\"gray\", linestyle=\"--\", alpha=0.5)\n",
    "for i in range(0, 11):\n",
    "    ax.axvline(x=i * -1, color=\"gray\", linestyle=\"--\", alpha=0.5)\n",
    "\n",
    "\n",
    "# Create a Black Vertical line at 21 days from the event\n",
    "ax.axvline(x=21, color=\"black\", linestyle=\"-\", alpha=0.5)\n",
    "ax.axvline(x=0, color=\"black\", linestyle=\"-\", alpha=0.5)\n",
    "\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
