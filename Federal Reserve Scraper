import os
import requests
from bs4 import BeautifulSoup
import urllib

# set the base url
base_url = "https://www.federalreserve.gov"
press_releases_url = f"{base_url}/newsevents/pressreleases.htm"

# create a folder for downloaded files
if not os.path.exists("memos"):
    os.makedirs("memos")

def download_file(url, directory):
    response = requests.get(url)
    file_name = os.path.join(directory, url.split("/")[-1])
    with open(file_name, 'wb') as f:
        f.write(response.content)

response = requests.get(press_releases_url)
soup = BeautifulSoup(response.text, 'html.parser')

# look for press release links
for link in soup.find_all('a'):
    href = link.get('href')
    if href and "pressrelease" in href:
        press_release_url = f"{base_url}{href}"
        press_release_response = requests.get(press_release_url)
        press_release_soup = BeautifulSoup(press_release_response.text, 'html.parser')
        
        # look for pdf links in each press release
        for pdf_link in press_release_soup.find_all('a'):
            pdf_href = pdf_link.get('href')
            if pdf_href and "pdf" in pdf_href:
                if 'http' not in pdf_href:
                    pdf_href = f"{base_url}{pdf_href}"
                print(f"Downloading: {pdf_href}")
                download_file(pdf_href, "memos")
