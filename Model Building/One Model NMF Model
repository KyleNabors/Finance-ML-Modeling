import os
import sys
import json
import logging
import time
from contextlib import contextmanager
import os
from multiprocessing import Process
import psutil

import numpy as np
import pandas as pd
from numpy.random import RandomState
from sklearn import decomposition
from sklearn.cluster import MiniBatchKMeans
from sklearn.datasets import fetch_olivetti_faces
from sklearn.linear_model import LogisticRegressionCV
from sklearn.metrics import f1_score
from sklearn.feature_extraction.text import TfidfVectorizer

import pyLDAvis.gensim
import gensim.downloader
from gensim import matutils, utils
from gensim.corpora import Dictionary
from gensim.models import CoherenceModel, LdaModel, TfidfModel
from gensim.models.basemodel import BaseTopicModel
from gensim.models.nmf import Nmf as GensimNmf
from gensim.parsing.preprocessing import preprocess_string

logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)

#Define Functions 
def load_data(file):    
    with open(file, "r", encoding="utf-8") as f:
        data = json.load(f)
    return data

# Write data to a JSON file
def write_data(file, data):
    with open(file, "w", encoding="utf-8") as f:
        json.dump(data, f, indent=4)

beige_books = load_data("/Users/kylenabors/Documents/MS-Thesis Data/Database/Fed Data/fed_data_blocks.json")

categories = [
    "interest",
    "inflation",
    "credit",
    "market",
    "trade"
]

dictionary = Dictionary(beige_books)
dictionary.filter_extremes(no_below=5, no_above=0.5, keep_n=20000)

tfidf = TfidfModel(dictionary=dictionary)
corpus = [
    dictionary.doc2bow(doc)
    for doc in beige_books
]
corpus_tfidf = list(tfidf[corpus])

nmf = GensimNmf(
    corpus=corpus_tfidf,
    num_topics=10,
    id2word=dictionary,
    chunksize=1000,
    passes=1,
    eval_every=10,
    minimum_probability=0,
    random_state=0,
    kappa=1,
)


nmf.show_topics()
nmf.get_topics()

#for topic in range(components_df.shape[0]):
#    tmp = components_df.iloc[topic]
#    print(f'For topic {topic+1} the words with the highest value are:')
#    print(tmp.nlargest(10))
#    print('\n')



# Save and load LDA Model
nmf.save("/Users/kylenabors/Documents/GitHub/MS-Thesis/Models/One Model/NMF Model.model")
#new_model = nmfmodel.load("/Users/kylenabors/Documents/GitHub/MS-Thesis/Models/One Model/NMF Model.model")
