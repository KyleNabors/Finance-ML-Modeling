# Import necessary libraries
import sys
import os
import json
import pdfplumber
import csv
from collections import defaultdict, Counter
from gensim.utils import simple_preprocess
from gensim.models import Word2Vec
import spacy
import csv
import nltk
from nltk.corpus import words

nlp = spacy.load("en_core_web_sm")

nltk.download('words')
hyphenated_words = set(word for word in words.words() if '-' in word)

# Define the path where config.py is located
config_path = '/Users/kylenabors/Documents/GitHub/MS-Thesis'

# Add this path to the sys.path
sys.path.append(config_path)

# Now Python knows where to find config.py
import config

#Variables, Paramaters, and Pathnames needed for this script
database_file = config.database

# Load data from the JSON database
def load_data(file):
    with open(file, "r", encoding="utf-8") as f:
        data = json.load(f)
    return data

# Write data to a JSON file
def write_data(file, data):
    with open(file, "w", encoding="utf-8") as f:
        json.dump(data, f, indent=4)

# Load the saved Word2Vec model
model = Word2Vec.load("/Users/kylenabors/Documents/GitHub/MS-Thesis/Models/Fed Models/fed_word2vec.model")

# Find the top 10 words similar to a given list of keywords
keywords = config.keywords
results = []
for keyword in keywords:
    res = model.wv.similar_by_word(keyword, topn=10)
    for item in res:
        results.append([keyword] + list(item))

# Save the results in a CSV file
with open('/Users/kylenabors/Documents/GitHub/MS-Thesis/Models/Fed Models/One Model/similar_words.csv', 'w', newline='') as file:
    writer = csv.writer(file)
    writer.writerow(["Keyword", "Similar Word", "Similarity"])
    writer.writerows(results)


# List to hold training data
train_data = []
keyword_dict = {keyword: i+1 for i, keyword in enumerate(keywords)}
keyword_freq = Counter()

# Filter the processed data based on search words
for segment in segments:
    for word in keywords:
        if word in segment:
            segment = " ".join(segment)
            train_data.append((segment, keyword_dict[word]))
            keyword_freq[word] += 1

# Write the training data to a JSON file
write_data("/Users/kylenabors/Documents/MS-Thesis Data/Database/Fed Data/fed_data_train.json", train_data)

# Write keyword information to a CSV file
with open("/Users/kylenabors/Documents/MS-Thesis Data/Database/Fed Data/keyword_info.csv", "w", newline="") as csvfile:
    fieldnames = ['Keyword', 'Number', 'Frequency']
    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)

    writer.writeheader()
    for keyword, number in keyword_dict.items():
        writer.writerow({'Keyword': keyword, 'Number': number, 'Frequency': keyword_freq[keyword]})

# Write keyword frequency by year-month and type to a CSV file
with open("/Users/kylenabors/Documents/MS-Thesis Data/Database/Fed Data/keyword_info_ts.csv", "w", newline="") as csvfile:
    fieldnames = ['Year-Month', 'Type', 'Keyword', 'Frequency']
    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)

    writer.writeheader()
    for year_month, doc_types in keyword_freq_ts.items():
        for doc_type, word_counts in doc_types.items():
            for keyword, freq in word_counts.items():
                if keyword in keywords:  # only write the selected keywords to the CSV
                    writer.writerow({'Year-Month': year_month, 'Type': doc_type, 'Keyword': keyword, 'Frequency': freq})
